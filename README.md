# TERM PROJECT (Image Captioning)

## GROUP 11 (Accuracy Achievers)
- **21CS10052** Pola Gnana Shekar
- **21CS10060** Simma Pavan Kumar
- **21CS30016** Chityala Raviteja
- **21CS30053** Sumanth Tadigoppala

---

# Part A: Image Captioning Using CNN Encoder and RNN Decoder.
An image captioning model using a Convolutional Neural Network (CNN) as an encoder and a Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) as a decoder. 

## How to run:
- Set the dataset (custom_caption_dataset) and copy its path to include in the model.
- Run each cell one after the other in the provided notebook.

## Note:
- This project is designed to be run on Kaggle. For testing purposes, it is recommended to use Kaggle.
- Ensure that the dataset path is correctly set in the notebook.
- In case of any issues, try enabling the "Internet" option in session settings, as this may resolve errors related to internet connectivity.
- The captions generated for the entire test dataset are present at the end of the notebook

---

# Part B: Image Captioning model using ViT encoder and Transformer Based Decoder.
An image captioning model using a Vision Transformer (ViT) encoder and a BERT-based decoder.

## How to run:
- Set the dataset (custom_caption_dataset) and copy its path to include in the model.
- Run each cell one after the other in the provided notebook.
- During the training phase you may be asked to enter an API key to access wand.ai for this we have included the API key that can be used in the markdown cell.

## Note:
- This project is designed to be run on Kaggle. For testing purposes, it is recommended to use Kaggle.
- Ensure that the dataset path is correctly set in the notebook.
- In case of any issues, try enabling the "Internet" option in session settings, as this may resolve errors related to internet connectivity.
- The **captions generated for the entire test dataset** are present in the **evaluation and results section**, in the cell just before calculating the metrics